{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Institutional Id for employees \n",
    "### Join two dataset using pandas dataframe and approximate string matching\n",
    "We have a dataset of Ethics certifications. It include different attribute like Title, researcher id (ucid), email address, name and so on. UCID are numeric value e.g., 10003462. However, some researchers do not have a numeric ucid. Instead they have text user name as ucid such as firstname.lastname as ucid. In this work, we separate those researchers and retrieve numeric ucid by joining ethics dataset with human resource (hr) dataset. \n",
    "\n",
    "We join the ethics and hr dataset based on the researcher's last name. We then compute the similarity score for names between two dataset using edit distance. We take the records that have similarity score more than a certain threshold. Records that pass the threshold can be further examined by human user to reduce false positives.\n",
    "\n",
    "Here is a snapshot of fields in two dataset:\n",
    "\n",
    "ethics [CertificateNumber,ShortStudyTitle,PI_UCID, PI_firstName,PI_lastName,CO_UCID,CO_firstName, CO_lastName,..]\n",
    "\n",
    "hcm [PERS_KEY, PERSFIRSTNAMES, PERSLASTNAMES, PERSEMAIL, ..]\n",
    "\n",
    "We denote hr dataset as hcm in this analysis. In ethics dataset, some researchers has text username instead of numeric id under the field PI_UCID and CO_UCID. Our objective is to retrieve those user's numeric id from the hr dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading ethics dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "d=''   #enter directory info\n",
    "fname='ethics_name_email.csv'\n",
    "ethics=pd.read_csv(os.path.join(d,fname))\n",
    "#print ethics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading hr dataset and call it hcm\n",
    "hcm_file='hcm.csv'    \n",
    "hcm=pd.read_csv(os.path.join(d,hcm_file))\n",
    "#hcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods for filtering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def takeTextUsername(df,col):\n",
    "    #Return dataframe that only contains text username under col\n",
    "    return df[df[col].apply(lambda x: not x.isdigit())]\n",
    "\n",
    "def drop_null_value(adf, col):\n",
    "    #Return a dataframe without null values under col\n",
    "    b=pd.isnull(adf[col])\n",
    "    b=b.map(lambda x: not x)\n",
    "    adf=adf[b]\n",
    "    return adf\n",
    "\n",
    "def drop_col(adf, col_ar):\n",
    "    #drop a list of columns from the dataframe; updates adf in place\n",
    "    #Return nothing\n",
    "    \n",
    "    for acol in col_ar:\n",
    "        adf.drop([acol],axis=1, inplace=True)\n",
    "    \n",
    "    #make distinct\n",
    "    adf.drop_duplicates(inplace=True)\n",
    "    \n",
    "def process_name(adf, col):\n",
    "    #Convert to lower case for each value of the col and adds a new column\n",
    "    #Return new column name\n",
    "    adf[col+'_l']=adf.apply(lambda x:x[col].lower(),axis=1)\n",
    "    return col+'_l'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approxmiate string matching\n",
    "We have used edit distance to compute similarity between strings. Edit distance between two strings is the number of insert, delete and replace operations required to transform one string to the other. Normalized distance is subtracted from 1 to compute similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s1,s2 - strings\n",
    "    Return:\n",
    "        edit distance between two strings\n",
    "    Collected from:\n",
    "    https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def similarity(s1,s2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s1,s2 - strings\n",
    "    Return:\n",
    "        normalized similarity score between two strings\n",
    "        Method is case sensitive\n",
    "    \"\"\"\n",
    "    denom=len(s1) if len(s1)>len(s2) else len(s2)\n",
    "    #return the normalized similarity score\n",
    "    sscore=1.0-(float(levenshtein(s1,s2))/denom)\n",
    "    return sscore\n",
    "\n",
    "def fun(ar_str):\n",
    "    '''Converts to lowercase, concatenates a list of strings \n",
    "    and returns concatenated string\n",
    "    Args:\n",
    "        ar_str: a list of String\n",
    "    Returns:\n",
    "        a single string\n",
    "    ''' \n",
    "    s=''\n",
    "    for ts in ar_str:\n",
    "        s+=ts.strip().lower()+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining ethics and hr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_col(ethi_df,eucid,e_fname, e_lname, hr_df, hucid, h_fname, h_lname):\n",
    "    '''Join ethi_df frame's record with the records of the hr_df frame. \n",
    "    Similarity score of the first name and last name are used in joining.\n",
    "    Args:\n",
    "        ethi_df: ethics dataset\n",
    "        eucid, e_fname, e_lname: ethics column containing ucid, first and last name\n",
    "        hr_df: hr dataset\n",
    "        hucid, h_fname, h_lname: hr column containing ucid, first and last name\n",
    "        \n",
    "    Returns:\n",
    "        a dataframe containing join output between ethi_df and hr_df\n",
    "    '''\n",
    "    \n",
    "    ethi_df=drop_null_value(ethi_df,eucid)\n",
    "    \n",
    "    #take only text user name\n",
    "    ethi_df=takeTextUsername(ethi_df,eucid)\n",
    "    \n",
    "    if debugFlag:\n",
    "        print 'dim before drop method ', ethi_df.shape\n",
    "    \n",
    "    '''\n",
    "       We drop a few columns like certificate number to reduce the number of rows\n",
    "       in the join. Researcher's records are repeated for each ethics certificate \n",
    "       they are part of. We drop certificate number and then take distinct records\n",
    "       using drop_col method\n",
    "    '''\n",
    "    drop_col(ethi_df,set(ethi_df.columns)-set([eucid,e_fname, e_lname,SFIELD]))\n",
    "    \n",
    "    if debugFlag:\n",
    "        print 'dim after drop method', ethi_df.shape\n",
    "        \n",
    "    # we will next join two data frame based on last name\n",
    "    # make last name lower case\n",
    "    #get only the last name of the investigator and make it a separate columbn\n",
    "    e_lname_l=process_name(ethi_df, e_lname)\n",
    "    \n",
    "    #get hcm column read; df is updated in place; return value is the new column name\n",
    "    h_lname_l=process_name(hr_df, h_lname)\n",
    "    \n",
    "    \n",
    "    #inner join ethics and hcm based on the last name\n",
    "    inner_matched=pd.merge(left=ethi_df, right=hr_df, left_on=e_lname_l,right_on=h_lname_l)     \n",
    "    \n",
    "    #compute the similarity based on first and last name between ethics and hr dataset\n",
    "    inner_matched['similarity']=inner_matched.apply(lambda x:similarity(fun([x[e_fname],x[e_lname]]), fun([x[h_fname],x[h_lname]])),axis=1)\n",
    "\n",
    "    #keep records that pass the similarity threshold MT\n",
    "    close_matched=inner_matched[inner_matched['similarity']>=MT]\n",
    "    return close_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find ucid for PI and COI fields, respectively. MT defines the threshold for similarity score. For privacy reasons, dataframes not previewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MT=.7    #similarity score threshold\n",
    "debugFlag=True\n",
    "\n",
    "#[1] find ucid for PI by mapping ethics to hr\n",
    "e=ethics.copy(deep=True)\n",
    "hr=hcm.copy(deep=True)\n",
    "SFIELD='pi_email_1'     #this field will not be dropped in the final output\n",
    "pi_df=map_col(e,'PI_UCID','PI_firstName','PI_lastName',hr,'PERS_KEY','PERSFIRSTNAMES','PERSLASTNAMES')\n",
    "\n",
    "#write the retrieved ucid to file\n",
    "matched_filename='hreba_hcm_close_matches_pi.csv'\n",
    "pi_df.to_csv(os.path.join(d,matched_filename),index=False)\n",
    "\n",
    "#[2] find ucid for COI by mapping ethics to hr\n",
    "e=ethics.copy(deep=True)\n",
    "hr=hcm.copy(deep=True)\n",
    "SFIELD='co_email_1'\n",
    "coi_df=map_col(e,'CO_UCID','CO_firstName','CO_lastName',hr,'PERS_KEY','PERSFIRSTNAMES','PERSLASTNAMES')\n",
    "\n",
    "#write the retrieved ucid to file\n",
    "matched_filename='hreba_hcm_close_matches_coi.csv'\n",
    "coi_df.to_csv(os.path.join(d,matched_filename),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
